{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gradient Decent.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPRhLWx3nK+tnzf4IEvcGls",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SamuelXJames/MLA/blob/main/Optimizers/Gradient_Decent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uB-4tXvkSYK6"
      },
      "source": [
        "# Stochastic Gadient Decent\r\n",
        "### Pros\r\n",
        "\r\n",
        "- Converges nicely\r\n",
        "\r\n",
        "### Cons\r\n",
        "- Common learning rate for all parameters\r\n",
        "- Generally slower than most other optimizers\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBXBHyIFaIaL"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5Anyz9WAtSx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d2f1071-166c-4bdd-e3c0-3084448c5b4d"
      },
      "source": [
        "!pip install gitdir\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "import seaborn as sns\r\n",
        "import os\r\n",
        "import requests\r\n",
        "from tensorflow.keras.optimizers import SGD\r\n",
        "from tensorflow.keras import layers as L\r\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gitdir in /usr/local/lib/python3.6/dist-packages (1.2.4)\n",
            "Requirement already satisfied: colorama~=0.4 in /usr/local/lib/python3.6/dist-packages (from gitdir) (0.4.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pE_hvsvEv1y"
      },
      "source": [
        "## SGD to Minimize an Arbitrary Function\r\n",
        "SGD to minimize a function "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZVpJGzvCUIf"
      },
      "source": [
        "# Function\r\n",
        "def fun(x1,x2):\r\n",
        "  y = x1 ** 2.0 - x1 * 3  + x2 ** 2\r\n",
        "  return y\r\n",
        "\r\n",
        "# Minimization\r\n",
        "def fu_min():\r\n",
        "  y = x1 ** 2.0 - x1 * 3  + x2 ** 2\r\n",
        "  return y\r\n",
        "\r\n",
        "# Initial Values\r\n",
        "def reset():\r\n",
        "  x1 = tf.Variable(10.0)\r\n",
        "  x2 = tf.Variable(10.0)\r\n",
        "  return x1,x2\r\n",
        "\r\n",
        "x1,x2 = reset()\r\n",
        "opt = SGD(learning_rate = 0.01) # Optimizer\r\n",
        "steps = 50\r\n",
        "\r\n",
        "# First Approach\r\n",
        "def approach_1():\r\n",
        "  for i in range(steps):\r\n",
        "    opt.minimize(fu_min, var_list = [x1,x2])\r\n",
        "    print('y = {:.1f}, x = {:.1f}, x2 = {:.1f}'.format(fun(x1,x2).numpy(),x1.numpy(),x2.numpy()))\r\n",
        "  return None\r\n",
        "\r\n",
        "# Second Approach\r\n",
        "def approach_2():\r\n",
        "  for i in range(steps):\r\n",
        "    with tf.GradientTape() as tape:\r\n",
        "      y = fun(x1,x2)\r\n",
        "    grads = tape.gradient(y,[x1,x2])\r\n",
        "    processed_grads = [g for g in grads]\r\n",
        "    grads_and_vars = zip(processed_grads, [x1,x2])\r\n",
        "    print ('y = {:.1f}, x1 = {:.1f}, x2 = {:.1f},  grads0 = {:.1f}, grads1 = {:.1f} '.format(y.numpy(), \r\n",
        "                                                                                            x1.numpy(), \r\n",
        "                                                                                            x2.numpy(), \r\n",
        "                                                                                            grads[0].numpy(), \r\n",
        "                                                                                            grads[1].numpy()))\r\n",
        "    opt.apply_gradients(grads_and_vars)\r\n",
        "  return None\r\n",
        "\r\n",
        "approach_2()\r\n",
        "  \r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-l4ebj6Ylq1"
      },
      "source": [
        "## Linear Regression (multivariable)\r\n",
        "Fit a line to some data\r\n",
        "[Help](https://stackoverflow.com/questions/36031324/how-to-implement-multivariate-linear-stochastic-gradient-descent-algorithm-in-te)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-rnB0zEFFzl"
      },
      "source": [
        " '''\r\n",
        " Boston Housing Data\r\n",
        " Variables in order:\r\n",
        " CRIM     per capita crime rate by town\r\n",
        " ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\r\n",
        " INDUS    proportion of non-retail business acres per town\r\n",
        " CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\r\n",
        " NOX      nitric oxides concentration (parts per 10 million)\r\n",
        " RM       average number of rooms per dwelling\r\n",
        " AGE      proportion of owner-occupied units built prior to 1940\r\n",
        " DIS      weighted distances to five Boston employment centres\r\n",
        " RAD      index of accessibility to radial highways\r\n",
        " TAX      full-value property-tax rate per $10,000\r\n",
        " PTRATIO  pupil-teacher ratio by town\r\n",
        " B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\r\n",
        " LSTAT    % lower status of the population\r\n",
        " MEDV     Median value of owner-occupied homes in $1000's\r\n",
        "\r\n",
        " '''\r\n",
        " \r\n",
        " \r\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.boston_housing.load_data()\r\n",
        "\r\n",
        "def calc_loss():\r\n",
        "  \r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFWiQu0ocBfY"
      },
      "source": [
        "## Nueral Network Misclassification\r\n",
        "Modifing images to be misclassified by neural networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lilIYUyPeMrQ",
        "outputId": "6532d2ef-800b-4e6c-cf64-c06d7c1ade6b"
      },
      "source": [
        "## DOWNLOADS DATA AND MODEL + PREPROCESSING\r\n",
        "\r\n",
        "if os.path.exists('/content/adversarial_example/sample_imgs/img_4.jpg'):\r\n",
        "  print('Images have already been dowloaded')\r\n",
        "else:\r\n",
        "  !gitdir https://github.com/SamuelXJames/toptal_tensorflow_blog_post/tree/dev/adversarial_example/sample_imgs\r\n",
        "  print('Finished donwloading images')\r\n",
        "\r\n",
        "if os.path.exists('./model.h5'):\r\n",
        "    print('Model already exists locally, no need to download again')\r\n",
        "else:\r\n",
        "    # Pre-trained model weights are stored in my S3 bucket\r\n",
        "    model_url = 'https://areiner-toptal-blog-resources.s3.amazonaws.com/dogs_and_cats/model.h5'\r\n",
        "    with open('model.h5', 'wb') as f:\r\n",
        "        f.write(requests.get(model_url).content)\r\n",
        "\r\n",
        "    print(f'Finished downloading model weights to \"model.h5\"')\r\n",
        "\r\n",
        "file_size_mb = os.stat('model.h5').st_size / (1024 * 1024.)\r\n",
        "print(f'Model weights file is {file_size_mb:.1f}MB')\r\n",
        "\r\n",
        "def generator():\r\n",
        "  IMG_SIZE_3D = [128,128,3]\r\n",
        "  x = inputs = L.Input(shape=IMG_SIZE_3D)\r\n",
        "  x = L.Conv2D(32, (3, 3), activation='relu', input_shape=IMG_SIZE_3D)(x)\r\n",
        "  x = L.BatchNormalization()(x)\r\n",
        "  x = L.MaxPooling2D(pool_size=(2, 2))(x)\r\n",
        "  x = L.Dropout(0.25)(x)\r\n",
        "\r\n",
        "  x = L.Conv2D(64, (3, 3), activation='relu')(x)\r\n",
        "  x = L.BatchNormalization()(x)\r\n",
        "  x = L.MaxPooling2D(pool_size=(2, 2))(x)\r\n",
        "  x = L.Dropout(0.25)(x)\r\n",
        "\r\n",
        "  x = L.Conv2D(128, (3, 3), activation='relu')(x)\r\n",
        "  x = L.BatchNormalization()(x)\r\n",
        "  x = L.MaxPooling2D(pool_size=(2, 2))(x)\r\n",
        "  x = L.Dropout(0.25)(x)\r\n",
        "\r\n",
        "  x = L.Flatten()(x)\r\n",
        "  x = L.Dense(512, activation='relu')(x)\r\n",
        "  x = L.BatchNormalization()(x)\r\n",
        "  x = L.Dropout(0.5)(x)\r\n",
        "\r\n",
        "  x = outputs = L.Dense(2, activation='softmax')(x)\r\n",
        "\r\n",
        "  model = tf.keras.Model(inputs=inputs, outputs=outputs)\r\n",
        "  return model\r\n",
        "\r\n",
        "# Preprocess Images\r\n",
        "folder = '/content/adversarial_example/sample_imgs/'\r\n",
        "IMG_SHAPE = [128,128]\r\n",
        "img_dir = os.listdir(folder)\r\n",
        "imgs = [img_to_array(load_img(os.path.join(folder,img))) for img in img_dir]\r\n",
        "imgs = [tf.image.resize(img,IMG_SHAPE) for img in imgs]\r\n",
        "imgs = tf.convert_to_tensor(imgs)\r\n",
        "\r\n",
        "# Load Model\r\n",
        "model = generator()\r\n",
        "model.load_weights('/content/model.h5')\r\n",
        "\r\n",
        "# Prediction\r\n",
        "def get_model_output(model, img3d):\r\n",
        "    # Add batch dimension to predict with model, then remove extra dim in result\r\n",
        "    return tf.squeeze(model.predict(tf.expand_dims(img3d, axis=0)))\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Images have already been dowloaded\n",
            "Model already exists locally, no need to download again\n",
            "Model weights file is 49.4MB\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f1bc139c488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6S8nw8f4sIjk",
        "outputId": "a205068c-a22b-4456-fb69-fd92575e504d"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([128, 128, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cY0N9Cne2emL"
      },
      "source": [
        "## Resources\r\n",
        "[Toptal](https://www.toptal.com/python/gradient-descent-in-tensorflow)\r\n",
        "\r\n",
        "[An overview of gradient descent optimization algorithms](https://ruder.io/optimizing-gradient-descent/index.html#otherrecentoptimizers)\r\n",
        "\r\n",
        "[3 different ways to Perform Gradient Descent in Tensorflow](https://medium.com/analytics-vidhya/3-different-ways-to-perform-gradient-descent-in-tensorflow-2-0-and-ms-excel-ffc3791a160a)"
      ]
    }
  ]
}